{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "https://haystack.deepset.ai/integrations/milvus-document-store\n",
    "https://haystack.deepset.ai/integrations/ollama"
   ],
   "id": "c495aa8e148bab0c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import MarkdownToDocument\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "from milvus_haystack import MilvusDocumentStore\n",
    "from milvus_haystack.milvus_embedding_retriever import MilvusEmbeddingRetriever"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:41:58.300535Z",
     "start_time": "2024-06-14T13:41:58.282136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "document_store = MilvusDocumentStore(\n",
    "    connection_args={\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"19530\",\n",
    "        \"user\": \"\",\n",
    "        \"password\": \"\",\n",
    "        \"secure\": False,\n",
    "    },\n",
    "    collection_name=\"scouting\",\n",
    "    vector_field=\"embeddings\"\n",
    ")\n"
   ],
   "id": "29bbc82467038f2e",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt_template = \"\"\"You are an scouting assistant in football (soccer). \n",
    "                    Answer the following query based on the provided context. If the context does\n",
    "                     not include an answer, reply with 'I don't know'. \\n\n",
    "                     Query: {{query}}\n",
    "                     Documents:\n",
    "                     {% for doc in documents %}\n",
    "                     Player-ID: {{doc.meta['player_transfermarkt_id']}}, Report-Content: {{ doc.content }} \\n###\\n \n",
    "                     {% endfor %}\n",
    "                     \n",
    "                     Give a short answer for every unique player-id from the provided documents and a summary about their reports.\n",
    "                     Answer: \n",
    "                  \"\"\""
   ],
   "id": "251cb3471463c0e1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from haystack.utils import Secret\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack_integrations.components.embedders.ollama.text_embedder import OllamaTextEmbedder\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"text_embedder\", OllamaTextEmbedder(model=\"nomic-embed-text\"))\n",
    "rag_pipeline.add_component(\"retriever\", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))\n",
    "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\n",
    "rag_pipeline.add_component(\"generator\", OllamaGenerator(model=\"mistral\", url=\"http://localhost:11434/api/generate\"))\n",
    "rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"generator\")\n",
    "\n",
    "question = \"I need an attacking winger, showcasing exceptional speed and technique.\"\n",
    "\n",
    "\n",
    "results = rag_pipeline.run(\n",
    "    {\n",
    "        \"text_embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"query\": question},\n",
    "    }\n",
    ")\n",
    "print('RAG answer:', results[\"generator\"][\"replies\"][0])\n"
   ],
   "id": "820b74616348b918",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Checking what we get back from queries\n",
    "from haystack_integrations.components.embedders.ollama.text_embedder import OllamaTextEmbedder\n",
    "# t=test. Wanted ot make sure i dont accidently use it in the other code\n",
    "t_query = \"Performed as an attacking winger, showcasing exceptional speed and technique.\"\n",
    "# used this embedding locally when importing aswell\n",
    "t_embedder = OllamaTextEmbedder(model=\"nomic-embed-text\")\n",
    "t_retriever = MilvusEmbeddingRetriever(document_store=document_store, top_k=3)\n",
    "                                \n",
    "t_embedding = t_embedder.run(t_query)[\"embedding\"]          \n",
    "t_retrieved_documents = t_retriever.run(t_embedding)\n",
    "\n",
    "t_prompt_builder = PromptBuilder(template=prompt_template)\n",
    "t_prompt = t_prompt_builder.run(template_variables={\"documents\": t_retrieved_documents['documents'],\"query\": question})\n",
    "print(t_prompt)\n"
   ],
   "id": "3ae1ce23d6638dc8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:03:44.729468Z",
     "start_time": "2024-06-14T14:03:44.720346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Trying to get structured output now\n",
    "# https://haystack.deepset.ai/tutorials/28_structured_output_with_loop\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class PlayerResponse(BaseModel):\n",
    "    player_id: int = Field(description=\"ID of the player\")\n",
    "    report_summary: str = Field(name=\"report_summary\",\n",
    "                                description=\"Summary of the reports that have the same player id\")\n",
    "\n",
    "\n",
    "# We want to get a list of players\n",
    "class ListPlayerResponse(BaseModel):\n",
    "    list: List[PlayerResponse]\n",
    "    \n",
    "\n",
    "json_schema = json.dumps(PlayerResponse.model_json_schema())\n",
    "json_schema\n"
   ],
   "id": "92319183d22f970f",
   "execution_count": 111,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:03:46.725608Z",
     "start_time": "2024-06-14T14:03:46.720084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import random\n",
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional, List\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "\n",
    "# Define the component input parameters\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    # Define the component output\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "        print(\"got to output validation\")\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        ## Try to parse the LLM's reply ##\n",
    "        # If the LLM's reply is a valid object, return `\"valid_replies\"`\n",
    "        try:\n",
    "            output_dict = json.loads(replies[0])\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": replies}\n",
    "\n",
    "        # If the LLM's reply is corrupted or not valid, return \"invalid_replies\" and the \"error_message\" for LLM to try again\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ],
   "id": "74833b1d529dbeb",
   "execution_count": 112,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Again postfix with _loop as not to infere with any other variables",
   "id": "9e90e6405f3e6cd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:05:27.780528Z",
     "start_time": "2024-06-14T14:05:27.773517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "prompt_template_loop = \"\"\"\n",
    "You are a scouting assistant in football (soccer). \n",
    "Answer the following query and create a JSON object from the information present in this context: \n",
    "Query: \n",
    "{{query}}\n",
    "\n",
    "\n",
    "Context:\n",
    "{% for doc in documents %}\n",
    "Player-ID: {{doc.meta['player_transfermarkt_id']}}, Report-Content: {{ doc.content }} \\n###\\n \n",
    "{% endfor %}\n",
    "                     \n",
    "Give a short answer for every unique player-id from the provided documents and a summary about their reports..\n",
    "Only use information that is present in the context. Follow this JSON schema, but only return the actual instances without any additional schema definition:\n",
    "{{schema}}\n",
    "Make sure your response is a dict and not a list.\n",
    "{% if invalid_replies and error_message %}\n",
    "  You already created the following output in a previous attempt: {{invalid_replies}}\n",
    "  However, this doesn't comply with the format requirements from above and triggered this Python exception: {{error_message}}\n",
    "  Correct the output and try again. Just return the corrected output without any extra explanations.\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder_loop = PromptBuilder(template=prompt_template_loop)\n"
   ],
   "id": "e4286b70c3439b9f",
   "execution_count": 117,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:05:28.929036Z",
     "start_time": "2024-06-14T14:05:28.921706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rag_pipeline_loop = Pipeline(max_loops_allowed=5)\n",
    "rag_pipeline_loop.add_component(\"text_embedder\", OllamaTextEmbedder(model=\"nomic-embed-text\"))\n",
    "rag_pipeline_loop.add_component(\"retriever\", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))\n",
    "rag_pipeline_loop.add_component(\"prompt_builder\", prompt_builder_loop)\n",
    "rag_pipeline_loop.add_component(\"llm\", OllamaGenerator(model=\"mistral\", url=\"http://localhost:11434/api/generate\"))\n",
    "output_validator = OutputValidator(pydantic_model=PlayerResponse)\n",
    "rag_pipeline_loop.add_component(instance=output_validator, name=\"output_validator\")\n",
    "\n",
    "\n",
    "rag_pipeline_loop.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline_loop.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "rag_pipeline_loop.connect(\"prompt_builder\", \"llm\")\n",
    "rag_pipeline_loop.connect(\"llm\", \"output_validator\")\n",
    "\n",
    "# If a component has more than one output or input, explicitly specify the connections:\n",
    "rag_pipeline_loop.connect(\"output_validator.invalid_replies\", \"prompt_builder.invalid_replies\")\n",
    "rag_pipeline_loop.connect(\"output_validator.error_message\", \"prompt_builder.error_message\")"
   ],
   "id": "59e39abc35a9f4b2",
   "execution_count": 118,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:42:09.455959Z",
     "start_time": "2024-06-14T13:42:08.739375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save pipeline overview in local directory\n",
    "rag_pipeline_loop.draw(\"auto-correct-pipeline.png\")"
   ],
   "id": "d4f964bb40186c62",
   "execution_count": 75,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T14:07:32.191055Z",
     "start_time": "2024-06-14T14:05:31.037526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question_loop = \"I need an attacking winger, showcasing exceptional speed and technique.\"\n",
    "\n",
    "# result = rag_pipeline_loop.run({\"prompt_builder\": {\"context\": passage, \"schema\": json_schema}})\n",
    "results = rag_pipeline_loop.run(\n",
    "    {\n",
    "        \"text_embedder\": {\"text\": question_loop},\n",
    "        \"prompt_builder\": {\"query\": question_loop, \"schema\": json_schema},\n",
    "    }\n",
    ")"
   ],
   "id": "807197a58ceb0b1b",
   "execution_count": 119,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
