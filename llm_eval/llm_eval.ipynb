{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-06T14:34:50.745421Z",
     "start_time": "2024-07-06T14:34:50.738774Z"
    }
   },
   "source": [
    "# Defining search parameters (llm used, prompt template)\n",
    "# the formatting of the documents is also a tunable knob i'd say. Thats why its not taken from the chain.py file but copied here again. We can play around with that formatting if it actually helps our llm if we format it in a specific way. But for now its in a different cell\n",
    "\n",
    "import model_definitions\n",
    "import prompt_templates\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "MODEL = \"mistral\" # can be replaed by grid search later\n",
    "prompt_template = prompt_templates.v005 #can be replaced by GS later\n",
    "file_name = \"test_structure.json\"\n",
    "parser = JsonOutputParser(pydantic_object=model_definitions.ListPlayerResponse)\n",
    "prompt_for_llm = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\", \"format_instructions\"],\n",
    ")\n",
    "\n",
    "model = Ollama(model=MODEL, format=\"json\")"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:21:30.543766Z",
     "start_time": "2024-07-06T14:21:30.537253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def format_documents(docs: [Document]):\n",
    "    casted_docs = []\n",
    "    for doc in docs: \n",
    "        casted_doc = Document(**doc)\n",
    "        casted_docs.append(casted_doc)\n",
    "        \n",
    "    # Create a dictionary to hold reports for each player ID\n",
    "    player_reports = defaultdict(list)\n",
    "\n",
    "    # Aggregate reports by player ID\n",
    "    for doc in casted_docs:\n",
    "        player_id = doc.metadata['player_transfermarkt_id']\n",
    "        report_content = doc.page_content\n",
    "        player_reports[player_id].append(report_content)\n",
    "\n",
    "    # Format the aggregated reports\n",
    "    formatted_reports = []\n",
    "    for player_id, reports in player_reports.items():\n",
    "        formatted_report = f\"Player ID: {player_id}\\n\"\n",
    "        for i, report in enumerate(reports, 1):\n",
    "            formatted_report += f\"Report {i}: {report}\\n\"\n",
    "        formatted_report += \"###\"\n",
    "        formatted_reports.append(formatted_report.strip())\n",
    "\n",
    "    # Join all formatted reports into a single string\n",
    "    return_string = \"\\n\\n\".join(formatted_reports)\n",
    "    #print(\"------------\\nAfter merging reports for each player:\\n\")\n",
    "    #print(return_string)\n",
    "    return return_string"
   ],
   "id": "b376a3d2846a451f",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:13:08.312414Z",
     "start_time": "2024-07-06T14:13:08.304769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "@dataclass(init=True)\n",
    "class QueryAndRetrievedDocuments:\n",
    "    query: str\n",
    "    retrieved_documents: List[Document]\n",
    "            \n",
    "\n",
    "@dataclass\n",
    "class DataModel:\n",
    "    data: List[QueryAndRetrievedDocuments]"
   ],
   "id": "fdbfcbc706936003",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:21:56.821630Z",
     "start_time": "2024-07-06T14:21:56.815136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Create the context\n",
    "def load_inputs() -> DataModel:\n",
    "    with open(file_name, \"r\") as file:\n",
    "        json_data = file.read()\n",
    "        parsed_data = json.loads(json_data)     \n",
    "        return parsed_data\n",
    "    "
   ],
   "id": "ccf13103f38e4393",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:22:03.543794Z",
     "start_time": "2024-07-06T14:22:03.535444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs: DataModel = load_inputs()\n",
    "print(inputs[0])"
   ],
   "id": "81aeb34b92d28d63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'my first query', 'retrieved_documents': [{'page_content': 'First page content!', 'metadata': {'id': 1, 'player_id': '12', 'player_transfermarkt_id': '123', 'scout_id': '0', 'grade_rating': 9.5, 'grade_potential': 10.0, 'main_position': 'centralmidfield', 'played_position': 'centralmidfield'}}, {'page_content': 'Second page content!', 'metadata': {'id': 1, 'player_id': '12', 'player_transfermarkt_id': '123', 'scout_id': '0', 'grade_rating': 9.5, 'grade_potential': 10.0, 'main_position': 'centralmidfield', 'played_position': 'centralmidfield'}}]}\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T14:13:08.333540Z",
     "start_time": "2024-07-06T14:13:08.329421Z"
    }
   },
   "cell_type": "code",
   "source": "print(inputs)",
   "id": "f1f927465e1bbe65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'my first query', 'retrieved_documents': [{'page_content': 'First page content!', 'metadata': {'id': 1, 'player_id': '12', 'player_transfermarkt_id': '123', 'scout_id': '0', 'grade_rating': 9.5, 'grade_potential': 10.0, 'main_position': 'centralmidfield', 'played_position': 'centralmidfield'}}]}]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-06T15:24:32.398269Z",
     "start_time": "2024-07-06T15:23:55.120496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model_definitions import ListPlayerResponse\n",
    "from evaluate import load\n",
    "\n",
    "# for all contexts format the documents so it conforms to the string passed to llm\n",
    "# then call llm\n",
    "# then we have a input/llm response pair\n",
    "# do all metrics on those\n",
    "# print result\n",
    "#\n",
    "\n",
    "def get_reports_from_context(query_and_retrieved_doc: QueryAndRetrievedDocuments, player_id: str) -> str:\n",
    "    return_string = \"\"\n",
    "    for doc in query_and_retrieved_doc['retrieved_documents']:\n",
    "        print(doc)\n",
    "        if doc['metadata']['player_transfermarkt_id'] == player_id:\n",
    "            print(doc)\n",
    "            return_string += \"Report:\"+ doc['page_content'] + \"\\n\"\n",
    "    \n",
    "    return return_string\n",
    "\n",
    "\n",
    "for singleInput in inputs:\n",
    "    actual_instance_of_input = QueryAndRetrievedDocuments(**singleInput)\n",
    "    formatted_context_string = format_documents(actual_instance_of_input.retrieved_documents)\n",
    "    \n",
    "    prompt_injection = {\"context\": formatted_context_string, \"question\": actual_instance_of_input.query, \"format_instructions\": parser.get_format_instructions()}\n",
    "    prompt_for_llm = prompt_template.format(**prompt_injection)\n",
    "    print(prompt_for_llm)\n",
    "    \n",
    "    model_answer = model.invoke(prompt_for_llm)\n",
    "    print(model_answer)\n",
    "    \n",
    "    model_json_answer = json.loads(model_answer)\n",
    "    print(model_json_answer)\n",
    "\n",
    "    player_response = ListPlayerResponse(**model_json_answer)\n",
    "    \n",
    "    \n",
    "    # Metrics\n",
    "    bertscore_metrics = []\n",
    "    berscore = load(\"bertscore\")\n",
    "    for player in player_response.list:\n",
    "        model_summary = player.report_summary\n",
    "        context_reports = get_reports_from_context(singleInput, str(player.player_id))\n",
    "        print(\"comparison now:\")\n",
    "        print(\"model_summary: \\n\\t\",model_summary)\n",
    "        print(\"initial reports: \\n\\t\",context_reports)\n",
    "        \n",
    "        # bertscore\n",
    "        predictions = [model_summary]\n",
    "        references = [context_reports]\n",
    "        # other model such as \"roberta-large\" is better, but larger obv (distilbert... takes 268MB vs roberta-large is 1.4GB)\n",
    "        print(\"bert score: \", berscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\"))\n",
    "    # for every player now check the metrics\n",
    "    # for list_item in model_json_answer:\n",
    "        \n",
    "\n"
   ],
   "id": "d9f8c147bfba4c53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant in football (soccer) scouting.\n",
      "    Use the following information to provide a concise answer to the question enclosed in <question> tags.\n",
      "    Dont make up anything that you dont see from the context.\n",
      "    \n",
      "    <context>\n",
      "    Player ID: 123\n",
      "Report 1: First page content!\n",
      "Report 2: Second page content!\n",
      "###\n",
      "    </context>\n",
      "\n",
      "    <question>\n",
      "    my first query\n",
      "    </question>\n",
      "\n",
      "   The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"PlayerResponse\": {\"properties\": {\"player_id\": {\"description\": \"ID of the player\", \"title\": \"Player Id\", \"type\": \"integer\"}, \"report_summary\": {\"description\": \"Summary of the reports that have the same player id\", \"name\": \"report_summary\", \"title\": \"Report Summary\", \"type\": \"string\"}}, \"required\": [\"player_id\", \"report_summary\"], \"title\": \"PlayerResponse\", \"type\": \"object\"}}, \"properties\": {\"list\": {\"items\": {\"$ref\": \"#/$defs/PlayerResponse\"}, \"title\": \"List\", \"type\": \"array\"}}, \"required\": [\"list\"]}\n",
      "```\n",
      "\n",
      "{\"list\": [{\"player_id\": 123, \"report_summary\": \"First page content!, Second page content!\"}]}\n",
      "{'list': [{'player_id': 123, 'report_summary': 'First page content!, Second page content!'}]}\n",
      "{'page_content': 'First page content!', 'metadata': {'id': 1, 'player_id': '12', 'player_transfermarkt_id': '123', 'scout_id': '0', 'grade_rating': 9.5, 'grade_potential': 10.0, 'main_position': 'centralmidfield', 'played_position': 'centralmidfield'}}\n",
      "{'page_content': 'First page content!', 'metadata': {'id': 1, 'player_id': '12', 'player_transfermarkt_id': '123', 'scout_id': '0', 'grade_rating': 9.5, 'grade_potential': 10.0, 'main_position': 'centralmidfield', 'played_position': 'centralmidfield'}}\n",
      "{'page_content': 'Second page content!', 'metadata': {'id': 1, 'player_id': '12', 'player_transfermarkt_id': '123', 'scout_id': '0', 'grade_rating': 9.5, 'grade_potential': 10.0, 'main_position': 'centralmidfield', 'played_position': 'centralmidfield'}}\n",
      "{'page_content': 'Second page content!', 'metadata': {'id': 1, 'player_id': '12', 'player_transfermarkt_id': '123', 'scout_id': '0', 'grade_rating': 9.5, 'grade_potential': 10.0, 'main_position': 'centralmidfield', 'played_position': 'centralmidfield'}}\n",
      "comparison now:\n",
      "model_summary: \n",
      "\t First page content!, Second page content!\n",
      "initial reports: \n",
      "\t Report:First page content!\n",
      "Report:Second page content!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af3a27d3733349d39847799b6f02e2cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bpoehlmann/workspace/envs/scouting/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b43667979e0a4c169c2eda700a26eb68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e761ec925084506a0f94d0642b9e295"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28433b63e3fa454591ebae7752746d9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a66e0a4a8cc4941b2e4aa23d11fe6b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert score:  {'precision': [0.9427976608276367], 'recall': [0.8977413773536682], 'f1': [0.9197180271148682], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=4.41.2)'}\n"
     ]
    }
   ],
   "execution_count": 107
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
